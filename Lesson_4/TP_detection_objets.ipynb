{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1973ec5f",
   "metadata": {},
   "source": [
    "# TP4 : Mise en pratique de la détection d'objets avec PyTorch et Hugging Face\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce TP, nous allons mettre en pratique les concepts de détection d'objets vus dans le cours. Vous allez apprendre à :\n",
    "1. Télécharger un modèle pré-entraîné de détection d'objets depuis Hugging Face\n",
    "2. Préparer et transformer des images pour l'inférence\n",
    "3. Exécuter le modèle pour obtenir des prédictions\n",
    "4. Analyser les tenseurs de sortie du modèle\n",
    "5. Implémenter l'algorithme de Non-Maximum Suppression (NMS)\n",
    "6. Visualiser les résultats avant et après l'application de NMS\n",
    "\n",
    "## Prérequis\n",
    "\n",
    "Assurez-vous d'avoir installé les bibliothèques nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothèques nécessaires\n",
    "!pip3 install torch torchvision transformers datasets pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0773d4d",
   "metadata": {},
   "source": [
    "## Partie 1 : Téléchargement et préparation du modèle\n",
    "\n",
    "Nous allons utiliser un modèle YOLO (You Only Look Once) compact depuis Hugging Face pour la détection d'objets. YOLO est un algorithme populaire pour la détection d'objets en temps réel qui prédit à la fois les boîtes englobantes et les classes des objets en une seule passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from transformers import AutoFeatureExtractor, AutoModelForObjectDetection\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import random\n",
    "\n",
    "# Téléchargement du modèle YOLOv5 depuis Hugging Face\n",
    "model_name = \"hustvl/yolos-tiny\"  # Un modèle léger de détection d'objets\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "model = AutoModelForObjectDetection.from_pretrained(model_name)\n",
    "\n",
    "# Vérification si CUDA est disponible et déplacement du modèle sur GPU si possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Modèle chargé et prêt à être utilisé sur {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6400f",
   "metadata": {},
   "source": [
    "## Partie 2 : Téléchargement et préparation des images\n",
    "\n",
    "Téléchargeons quelques images pour tester notre modèle de détection d'objets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs des images à tester\n",
    "image_urls = [\n",
    "    \"https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/zidane.jpg\",\n",
    "    \"https://raw.githubusercontent.com/ultralytics/yolov5/master/data/images/bus.jpg\",\n",
    "]\n",
    "\n",
    "# Téléchargement et préparation des images\n",
    "images = []\n",
    "original_images = []\n",
    "\n",
    "for url in image_urls:\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    original_images.append(img.copy())\n",
    "    images.append(img)\n",
    "\n",
    "# Affichage des images originales\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, img in enumerate(original_images):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Image {i+1}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00cdbd",
   "metadata": {},
   "source": [
    "## Partie 3 : Inférence avec le modèle\n",
    "\n",
    "Maintenant, nous allons passer les images à travers notre modèle et récupérer les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0143971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'inférence\n",
    "def run_inference(image, feature_extractor, model, device):\n",
    "    # Préparation de l'image\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Exécution du modèle\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "# Exécuter l'inférence sur nos images\n",
    "results = []\n",
    "for img in images:\n",
    "    output = run_inference(img, feature_extractor, model, device)\n",
    "    results.append(output)\n",
    "\n",
    "print(\"Inférence terminée pour toutes les images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b774c87",
   "metadata": {},
   "source": [
    "## Partie 4 : Analyse des tenseurs de sortie du modèle\n",
    "\n",
    "Analysons maintenant les tenseurs de sortie pour comprendre comment notre modèle représente les objets détectés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a318aafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinons la structure des sorties du modèle\n",
    "def analyze_model_output(output):\n",
    "    print(\"Structure de sortie du modèle :\")\n",
    "    for key, value in output.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"{key}: Tensor de forme {value.shape}, type {value.dtype}\")\n",
    "        else:\n",
    "            print(f\"{key}: {type(value)}\")\n",
    "    \n",
    "    # Examinons les prédictions (logits)\n",
    "    pred_logits = output.logits[0]  # Forme: [num_queries, num_classes]\n",
    "    pred_boxes = output.pred_boxes[0]  # Forme: [num_queries, 4]\n",
    "    \n",
    "    print(f\"\\nNombre de boîtes prédites: {pred_boxes.shape[0]}\")\n",
    "    print(f\"Nombre de classes: {pred_logits.shape[1]}\")\n",
    "    \n",
    "    return pred_logits, pred_boxes\n",
    "\n",
    "# Analysons la sortie pour la première image\n",
    "pred_logits, pred_boxes = analyze_model_output(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f460d4",
   "metadata": {},
   "source": [
    "### À vous de jouer ! Analysez les tenseurs de sortie\n",
    "\n",
    "À partir de l'analyse précédente, répondez aux questions suivantes :\n",
    "\n",
    "1. Quelle est la forme des tenseurs `pred_logits` et `pred_boxes` ?\n",
    "2. Que représente chaque dimension de ces tenseurs ?\n",
    "3. Comment sont encodées les coordonnées des boîtes ?\n",
    "\n",
    "Complétez le code ci-dessous pour extraire les détections pertinentes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f0335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# À COMPLÉTER : Extrayez les scores et les boîtes englobantes\n",
    "def extract_predictions(results, image, threshold=0.5):\n",
    "    # Récupération des classes et des noms\n",
    "    id2label = model.config.id2label\n",
    "    \n",
    "    # On récupère les prédictions\n",
    "    outputs = results\n",
    "    \n",
    "    # Conversion en probabilités avec softmax\n",
    "    probas = outputs.logits.softmax(-1)[0, :, :-1]  # Dernier indice est pour \"no object\"\n",
    "    \n",
    "    # À COMPLÉTER : Récupérez le score maximum et l'indice de classe pour chaque boîte\n",
    "    scores = # ...\n",
    "    labels = # ...\n",
    "    \n",
    "    # Filtrage des prédictions par score\n",
    "    # À COMPLÉTER : Filtrez les scores en fonction du seuil\n",
    "    keep = # ...\n",
    "    \n",
    "    # Récupération des boîtes au format (x1, y1, x2, y2)\n",
    "    boxes = outputs.pred_boxes[0, keep].cpu()\n",
    "    \n",
    "    # Conversion des boîtes au format normalisé de l'image\n",
    "    # À COMPLÉTER : Convertissez les coordonnées\n",
    "    h, w = image.size[::-1]\n",
    "    scaled_boxes = # ...\n",
    "    \n",
    "    return scaled_boxes, scores[keep], labels[keep], [id2label[i.item()] for i in labels[keep]]\n",
    "\n",
    "# Test de notre fonction d'extraction\n",
    "# À COMPLÉTER : Utilisez la fonction extract_predictions pour obtenir les détections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d571e",
   "metadata": {},
   "source": [
    "## Partie 5 : Implémentation de Non-Maximum Suppression (NMS)\n",
    "\n",
    "Les modèles de détection d'objets produisent souvent plusieurs détections pour un même objet. L'algorithme de NMS permet de filtrer ces détections redondantes en ne conservant que les plus pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee15bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# À COMPLÉTER : Implémentez l'algorithme de NMS\n",
    "def non_maximum_suppression(boxes, scores, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Implémentation de l'algorithme Non-Maximum Suppression\n",
    "    \n",
    "    Args:\n",
    "        boxes: Tenseur des boîtes englobantes au format (x1, y1, x2, y2)\n",
    "        scores: Tenseur des scores de confiance pour chaque boîte\n",
    "        threshold: Seuil d'IoU pour supprimer les boîtes redondantes\n",
    "    \n",
    "    Returns:\n",
    "        indices: Indices des boîtes à conserver\n",
    "    \"\"\"\n",
    "    # S'il n'y a pas de boîtes, retourner une liste vide\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Conversion en numpy si nécessaire\n",
    "    if isinstance(boxes, torch.Tensor):\n",
    "        boxes = boxes.cpu().numpy()\n",
    "    if isinstance(scores, torch.Tensor):\n",
    "        scores = scores.cpu().numpy()\n",
    "    \n",
    "    # À COMPLÉTER : Triez les boîtes par score (ordre décroissant)\n",
    "    # ...\n",
    "    \n",
    "    # Calculez l'aire de chaque boîte\n",
    "    # À COMPLÉTER: Calculez les aires des boîtes\n",
    "    # ...\n",
    "    \n",
    "    # Liste pour stocker les indices des boîtes à conserver\n",
    "    keep = []\n",
    "    \n",
    "    # Tant qu'il reste des boîtes à traiter\n",
    "    # À COMPLÉTER: Implémentez l'algorithme NMS\n",
    "    # ...\n",
    "    \n",
    "    return keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5afa784",
   "metadata": {},
   "source": [
    "## Partie 6 : Visualisation des détections avant et après NMS\n",
    "\n",
    "Visualisons maintenant les détections avant et après application de l'algorithme NMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9b616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser les boîtes\n",
    "def visualize_predictions(image, boxes, scores, classes, title=\"Détections\"):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Affichage de chaque boîte\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        # Création d'un rectangle\n",
    "        rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Affichage du texte\n",
    "        plt.text(x1, y1, f'{cls}: {score:.2f}', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Préparation des résultats avant NMS\n",
    "def process_and_visualize(image_idx, threshold=0.3, nms_threshold=0.5):\n",
    "    image = original_images[image_idx]\n",
    "    result = results[image_idx]\n",
    "    \n",
    "    # Extraction des prédictions\n",
    "    # À COMPLÉTER : Utilisez votre fonction extract_predictions ici\n",
    "    # ...\n",
    "    \n",
    "    # Visualisation avant NMS\n",
    "    visualize_predictions(image, boxes, scores, class_names, title=\"Détections avant NMS\")\n",
    "    \n",
    "    # Application de NMS\n",
    "    # À COMPLÉTER : Utilisez votre fonction non_maximum_suppression ici\n",
    "    # ...\n",
    "    \n",
    "    # Visualisation après NMS\n",
    "    # À COMPLÉTER : Visualisez les résultats après NMS\n",
    "    # ...\n",
    "\n",
    "# Test sur les trois images\n",
    "for i in range(len(images)):\n",
    "    process_and_visualize(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfed24",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans ce TP, vous avez appris à :\n",
    "1. Utiliser un modèle de détection d'objets pré-entraîné via Hugging Face\n",
    "2. Analyser les tenseurs de sortie d'un modèle de détection\n",
    "3. Implémenter l'algorithme de Non-Maximum Suppression (NMS) pour filtrer les détections redondantes\n",
    "4. Visualiser les résultats de détection\n",
    "\n",
    "Ces compétences sont essentielles pour travailler avec des modèles de vision par ordinateur dans des applications réelles.\n",
    "\n",
    "## Exercices supplémentaires\n",
    "\n",
    "1. Essayez de modifier le seuil de confiance pour les détections. Comment cela affecte-t-il les résultats ?\n",
    "2. Testez différents seuils pour l'algorithme NMS. Quel impact cela a-t-il sur les détections finales ?\n",
    "3. Essayez d'implémenter d'autres métriques pour évaluer la qualité des détections, comme la précision moyenne (mAP).\n",
    "4. Testez le modèle sur vos propres images. Quelles sont ses forces et ses faiblesses ? "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
