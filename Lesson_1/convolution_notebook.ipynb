{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions en Vision par Ordinateur\n",
    "\n",
    "Ce notebook explore les opérations de convolution et leur application dans les réseaux de neurones convolutifs (CNN).\n",
    "\n",
    "## Plan du notebook :\n",
    "1. Introduction aux convolutions\n",
    "2. Implémentation manuelle des convolutions\n",
    "3. Application de filtres sur des images MNIST\n",
    "4. Couches convolutives avec PyTorch\n",
    "5. Entraînement d'une couche convolutive sur des données synthétiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Configuration matplotlib pour de meilleurs affichages\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction aux Convolutions\n",
    "\n",
    "La convolution est une opération mathématique fondamentale en vision par ordinateur. Elle combine une image avec un filtre (noyau) pour extraire des caractéristiques spécifiques.\n",
    "\n",
    "Formellement, la convolution 2D est définie par :\n",
    "\n",
    "$(f * k)(x,y) = \\sum_{i=-a}^a \\sum_{j=-b}^b f(x-i,y-j)k(i,j)$\n",
    "\n",
    "où $f$ est l'image d'entrée et $k$ est le noyau de convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implémentation Manuelle des Convolutions\n",
    "\n",
    "Commençons par implémenter manuellement l'opération de convolution 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_conv2d(image, kernel):\n",
    "    \"\"\"Calcule manuellement la convolution 2D.\"\"\"\n",
    "    # Récupérer les dimensions\n",
    "    i_height, i_width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    \n",
    "    # Calculer le padding nécessaire\n",
    "    pad_h = k_height // 2\n",
    "    pad_w = k_width // 2\n",
    "    \n",
    "    # Créer la matrice de sortie\n",
    "    output = np.zeros_like(image, dtype=float)\n",
    "    \n",
    "    # Padding de l'image d'entrée\n",
    "    padded_image = np.pad(image, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant')\n",
    "    \n",
    "    # Effectuer la convolution\n",
    "    for i in range(i_height):\n",
    "        for j in range(i_width):\n",
    "            # Extraire la région\n",
    "            region = padded_image[i:i+k_height, j:j+k_width]\n",
    "            # Calculer la convolution pour cette position\n",
    "            output[i, j] = np.sum(region * kernel)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du Processus de Convolution\n",
    "\n",
    "Visualisons étape par étape comment fonctionne une convolution sur un exemple simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une matrice d'entrée simple (5x5)\n",
    "input_matrix = np.zeros((5, 5))\n",
    "input_matrix[1:4, 1:4] = 1  # Carré blanc au centre\n",
    "\n",
    "# Définir un noyau de détection de contours vertical (3x3)\n",
    "kernel = np.array([[-1, 0, 1],\n",
    "                    [-2, 0, 2],\n",
    "                    [-1, 0, 1]])\n",
    "\n",
    "# Appliquer la convolution\n",
    "result = manual_conv2d(input_matrix, kernel)\n",
    "\n",
    "# Visualiser l'entrée, le noyau et le résultat\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(input_matrix)\n",
    "axes[0].set_title(\"Image d'entrée\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(kernel)\n",
    "axes[1].set_title(\"Noyau (Sobel vertical)\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(result)\n",
    "axes[2].set_title(\"Résultat de la convolution\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration de la Convolution sur une Position Spécifique\n",
    "\n",
    "Voyons en détail comment une valeur spécifique est calculée lors de la convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser le calcul d'un pixel spécifique\n",
    "def visualize_convolution_step(input_matrix, kernel, position):\n",
    "    # Extraire les dimensions\n",
    "    k_height, k_width = kernel.shape\n",
    "    pad_h, pad_w = k_height // 2, k_width // 2\n",
    "    \n",
    "    # Padding de l'image\n",
    "    padded = np.pad(input_matrix, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant')\n",
    "    \n",
    "    # Position dans l'image paddée\n",
    "    i, j = position\n",
    "    padded_i, padded_j = i + pad_h, j + pad_w\n",
    "    \n",
    "    # Extraire la région pour la convolution\n",
    "    region = padded[padded_i-pad_h:padded_i+pad_h+1, padded_j-pad_w:padded_j+pad_w+1]\n",
    "    \n",
    "    # Calcul de la valeur\n",
    "    result_value = np.sum(region * kernel)\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
    "    \n",
    "    # Image originale avec la position marquée\n",
    "    axes[0].imshow(input_matrix)\n",
    "    axes[0].plot(j, i, 'ro', markersize=10)\n",
    "    axes[0].set_title(\"Position de calcul (rouge)\")\n",
    "    \n",
    "    # Région extraite\n",
    "    axes[1].imshow(region)\n",
    "    axes[1].set_title(\"Région extraite\")\n",
    "    \n",
    "    # Noyau\n",
    "    axes[2].imshow(kernel)\n",
    "    axes[2].set_title(\"Noyau\")\n",
    "    \n",
    "    # Calcul détaillé\n",
    "    axes[3].axis('off')\n",
    "    calculation = f\"Calcul de la convolution:\\n\\n\"\n",
    "    calculation += f\"Région:\\n{region}\\n\\n\"\n",
    "    calculation += f\"Noyau:\\n{kernel}\\n\\n\"\n",
    "    calculation += f\"Produit élément par élément:\\n{region * kernel}\\n\\n\"\n",
    "    calculation += f\"Somme: {result_value}\"\n",
    "    axes[3].text(0.1, 0.5, calculation, fontsize=12, family='monospace', verticalalignment='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return result_value\n",
    "\n",
    "# Visualiser le calcul pour une position au bord du carré\n",
    "result_value = visualize_convolution_step(input_matrix, kernel, (1, 2))\n",
    "print(f\"Valeur calculée à la position (1, 2): {result_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Application de Filtres sur des Images MNIST\n",
    "\n",
    "Téléchargeons le dataset MNIST et appliquons différents filtres de convolution sur ces images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger MNIST\n",
    "mnist_data = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "print(f\"Données MNIST chargées: {len(mnist_data)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner quelques exemples\n",
    "sample_indices = [0, 1, 2, 3]  # Indices des images à afficher\n",
    "samples = [mnist_data.data[i].numpy() for i in sample_indices]\n",
    "labels = [mnist_data.targets[i].item() for i in sample_indices]\n",
    "\n",
    "# Afficher les exemples\n",
    "fig, axes = plt.subplots(1, len(samples), figsize=(15, 3))\n",
    "for i, (img, lbl) in enumerate(zip(samples, labels)):\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Chiffre: {lbl}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition et Application de Différents Filtres\n",
    "\n",
    "Appliquons différents noyaux de convolution sur une image MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir une image de test\n",
    "test_digit = samples[0].astype(np.float32)\n",
    "\n",
    "# Définir différents noyaux\n",
    "kernels = {\n",
    "    \"Sobel vertical\": np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32),\n",
    "    \"Sobel horizontal\": np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32),\n",
    "    \"Flou (moyenne)\": np.ones((3, 3), dtype=np.float32) / 9,\n",
    "    \"Laplacien\": np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=np.float32),\n",
    "    \"Accentuation\": np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)\n",
    "}\n",
    "\n",
    "# Appliquer chaque filtre\n",
    "results = {name: manual_conv2d(test_digit, kernel) for name, kernel in kernels.items()}\n",
    "\n",
    "# Afficher les résultats\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Image originale\n",
    "axes[0].imshow(test_digit)\n",
    "axes[0].set_title(\"Image originale\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Images filtrées\n",
    "for i, (name, result) in enumerate(results.items(), 1):\n",
    "    axes[i].imshow(result)\n",
    "    axes[i].set_title(name)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Convolutions avec PyTorch\n",
    "\n",
    "Maintenant, utilisons PyTorch pour effectuer des convolutions et comparons les résultats avec notre implémentation manuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir l'image et le noyau en tenseurs PyTorch\n",
    "def torch_convolution(image, kernel):\n",
    "    \"\"\"Applique une convolution en utilisant PyTorch.\"\"\"\n",
    "    # Convertir en tenseurs\n",
    "    image_tensor = torch.from_numpy(image).float().unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, H, W]\n",
    "    kernel_tensor = torch.from_numpy(kernel).float().unsqueeze(0).unsqueeze(0)  # Shape: [1, 1, K_H, K_W]\n",
    "    \n",
    "    # Appliquer la convolution\n",
    "    result = F.conv2d(image_tensor, kernel_tensor, padding='same')\n",
    "    \n",
    "    # Convertir le résultat en numpy\n",
    "    return result.squeeze().numpy()\n",
    "\n",
    "# Comparer les résultats de notre implémentation avec PyTorch\n",
    "kernel_name = \"Sobel vertical\"\n",
    "kernel = kernels[kernel_name]\n",
    "\n",
    "manual_result = manual_conv2d(test_digit, kernel)\n",
    "torch_result = torch_convolution(test_digit, kernel)\n",
    "\n",
    "# Afficher la comparaison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(test_digit)\n",
    "axes[0].set_title(\"Image originale\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(manual_result)\n",
    "axes[1].set_title(f\"Convolution manuelle ({kernel_name})\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(torch_result)\n",
    "axes[2].set_title(f\"Convolution PyTorch ({kernel_name})\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Vérifier si les résultats sont similaires\n",
    "difference = np.abs(manual_result - torch_result)\n",
    "print(f\"Différence maximale: {difference.max()}\")\n",
    "print(f\"Différence moyenne: {difference.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entraînement d'une Couche de Convolution avec PyTorch\n",
    "\n",
    "Nous allons maintenant créer des données synthétiques et entraîner une couche de convolution pour détecter des motifs spécifiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Génération de Données Synthétiques\n",
    "\n",
    "Générons deux classes d'images:\n",
    "1. Images avec des lignes verticales\n",
    "2. Images avec des lignes horizontales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(num_samples=1000, image_size=28, noise_level=0.1):\n",
    "    \"\"\"Génère des données synthétiques: lignes verticales (classe 0) et horizontales (classe 1).\"\"\"\n",
    "    X = np.zeros((num_samples, 1, image_size, image_size), dtype=np.float32)\n",
    "    y = np.zeros(num_samples, dtype=np.int64)\n",
    "    \n",
    "    # Pour chaque échantillon\n",
    "    for i in range(num_samples):\n",
    "        # Décider aléatoirement de la classe\n",
    "        class_id = i % 2  # Alterner entre classe 0 et 1\n",
    "        y[i] = class_id\n",
    "        \n",
    "        # Générer l'image\n",
    "        if class_id == 0:  # Lignes verticales\n",
    "            # Choisir des positions aléatoires pour les lignes\n",
    "            positions = np.random.choice(range(2, image_size-2), size=3, replace=False)\n",
    "            for pos in positions:\n",
    "                X[i, 0, :, pos:pos+2] = 1.0\n",
    "        else:  # Lignes horizontales\n",
    "            # Choisir des positions aléatoires pour les lignes\n",
    "            positions = np.random.choice(range(2, image_size-2), size=3, replace=False)\n",
    "            for pos in positions:\n",
    "                X[i, 0, pos:pos+2, :] = 1.0\n",
    "        \n",
    "        # Ajouter du bruit\n",
    "        X[i, 0] += noise_level * np.random.randn(image_size, image_size)\n",
    "        \n",
    "        # Normaliser entre 0 et 1\n",
    "        X[i, 0] = np.clip(X[i, 0], 0, 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Générer des données d'entraînement et de test\n",
    "X_train, y_train = generate_synthetic_data(num_samples=1000)\n",
    "X_test, y_test = generate_synthetic_data(num_samples=200)\n",
    "\n",
    "# Convertir en tenseurs PyTorch\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "# Créer des datasets et dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Visualiser quelques exemples\n",
    "def show_examples(X, y, num_examples=5):\n",
    "    fig, axes = plt.subplots(2, num_examples, figsize=(15, 6))\n",
    "    \n",
    "    for cls in range(2):\n",
    "        # Trouver les indices des exemples de cette classe\n",
    "        indices = np.where(y == cls)[0][:num_examples]\n",
    "        \n",
    "        for i, idx in enumerate(indices):\n",
    "            axes[cls, i].imshow(X[idx, 0])\n",
    "            axes[cls, i].set_title(f\"Classe {cls}\")\n",
    "            axes[cls, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_examples(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Définition du Modèle CNN Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Une seule couche de convolution avec 2 filtres 3x3\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, padding=1)\n",
    "        # Couche de pooling pour réduire la dimension\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Couche entièrement connectée pour la classification\n",
    "        self.fc = nn.Linear(2 * 14 * 14, 2)  # 2 filtres, image 14x14 après pooling\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution et activation\n",
    "        x = F.relu(self.conv(x))\n",
    "        # Pooling\n",
    "        x = self.pool(x)\n",
    "        # Aplatir\n",
    "        x = x.view(-1, 2 * 14 * 14)\n",
    "        # Classification\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def get_filters(self):\n",
    "        \"\"\"Récupère les filtres appris.\"\"\"\n",
    "        return self.conv.weight.data.cpu().numpy()\n",
    "\n",
    "# Créer le modèle\n",
    "model = SimpleCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Fonction d'entraînement\n",
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # Réinitialiser les gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass et optimisation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistiques\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "# Fonction d'évaluation\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy de test: {accuracy:.4f}\")\n",
    "    return accuracy\n",
    "\n",
    "# Entraîner le modèle\n",
    "losses, accuracies = train(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "# Évaluer sur les données de test\n",
    "test_accuracy = evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualisation des Filtres Appris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les filtres appris\n",
    "filters = model.get_filters()\n",
    "print(f\"Forme des filtres: {filters.shape}\")\n",
    "\n",
    "# Afficher les filtres\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
    "for i in range(2):\n",
    "    filter_img = filters[i, 0]\n",
    "    axes[i].imshow(filter_img)\n",
    "    axes[i].set_title(f\"Filtre {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Afficher les valeurs numériques\n",
    "    for y in range(filter_img.shape[0]):\n",
    "        for x in range(filter_img.shape[1]):\n",
    "            axes[i].text(x, y, f\"{filter_img[y, x]:.2f}\", \n",
    "                         ha='center', va='center', \n",
    "                         color='white' if abs(filter_img[y, x]) > 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Visualisation des Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une version du modèle pour extraire les feature maps\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            original_model.conv,\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "feature_extractor = FeatureExtractor(model)\n",
    "\n",
    "# Visualiser les feature maps pour quelques exemples de test\n",
    "def visualize_feature_maps(model, X, y, num_examples=2):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for cls in range(2):\n",
    "            # Trouver un exemple de cette classe\n",
    "            idx = np.where(y == cls)[0][0]\n",
    "            sample = torch.from_numpy(X[idx:idx+1])\n",
    "            \n",
    "            # Obtenir les feature maps\n",
    "            feature_maps = model(sample).squeeze().numpy()\n",
    "            \n",
    "            # Afficher l'image d'entrée\n",
    "            axes[cls, 0].imshow(X[idx, 0])\n",
    "            axes[cls, 0].set_title(f\"Entrée (Classe {cls})\")\n",
    "            axes[cls, 0].axis('off')\n",
    "            \n",
    "            # Afficher les feature maps\n",
    "            for i in range(2):\n",
    "                axes[cls, i+1].imshow(feature_maps[i])\n",
    "                axes[cls, i+1].set_title(f\"Feature Map {i+1}\")\n",
    "                axes[cls, i+1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_feature_maps(feature_extractor, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook nous a permis d'explorer en profondeur les convolutions:\n",
    "\n",
    "1. Nous avons implémenté manuellement l'opération de convolution 2D\n",
    "2. Nous avons appliqué différents filtres sur des images MNIST\n",
    "3. Nous avons comparé notre implémentation avec celle de PyTorch\n",
    "4. Nous avons créé un modèle simple CNN et l'avons entraîné sur des données synthétiques\n",
    "5. Nous avons visualisé les filtres appris et les feature maps générées\n",
    "\n",
    "Les convolutions sont à la base de nombreuses applications en vision par ordinateur. Elles permettent d'extraire des caractéristiques locales des images, ce qui est particulièrement utile pour des tâches telles que la classification d'images, la détection d'objets, et la segmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
